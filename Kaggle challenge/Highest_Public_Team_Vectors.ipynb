{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook, set to produice prediction for the model with the highest accuracy on the private leaderboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#@title Installation\n",
    "!pip install --quie ipdb # debug\n",
    "!pip install --quie ipython-autotime  # timming\n",
    "!pip install --quie optuna  # hyperparaeters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='red'>You need to run the cell below twice before to proceed </font>\n",
    "If you can an error, running the cell bellow, please just re-run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 6.07 ms\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "np.random.seed(54321)\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from kernels.basic import Linear, Polynomial\n",
    "from kernels.regular import rbf_kernel, Exponential, Laplacian, RationalQuadratic, \\\n",
    "                            InverseMultiquadratic, Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',') #we will use this data set later to validate our model\n",
    "\n",
    "# X_train_mat=pd.read_csv('./data/Xtr_mat100.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test_mat=pd.read_csv('./data/Xte_mat100.csv', sep=',') #we will use this data set later to validate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                                seq\n",
       "1995  1995  TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...\n",
       "1996  1996  ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...\n",
       "1997  1997  TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...\n",
       "1998  1998  CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...\n",
       "1999  1999  TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.69 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataset is: (2000, 2)\n",
      "The shape of the Y_train dataset is: (2000, 2)\n",
      "time: 1.07 ms\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the X_train dataset is:',X_train.shape)\n",
    "print('The shape of the Y_train dataset is:',Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression (RR)\n",
    "\n",
    "class solveRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "            \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        A = (X.T.dot(X)) + np.eye(p)*lam*n\n",
    "        b = X.T.dot(y)\n",
    "        \n",
    "        self.beta = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Weighted Ridge Regression (WRR)\n",
    "class solveWRR():\n",
    "    def __init__(self, X, y, w, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.w = w\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        w = self.w\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == len(w) == n)\n",
    "\n",
    "        y1 = np.sqrt(w) * y\n",
    "        X1 = (np.sqrt(w) * X.T).T\n",
    "        \n",
    "        # Hint:\n",
    "        # Find y1 and X1 such that:\n",
    "        \n",
    "        self.beta = solveRR(X1, y1, lam).fit()\n",
    "                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class solveLRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "    \n",
    "        lam = self.lam \n",
    "        max_iter = 50\n",
    "        eps = 1e-3\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize\n",
    "        self.beta = np.zeros(p)\n",
    "\n",
    "        # Hint: Use IRLS\n",
    "        for i in range(max_iter):\n",
    "            beta_old = self.beta\n",
    "            f = X.dot(beta_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*f)\n",
    "            self.beta = solveWRR(X, z, w, 2*lam).fit()\n",
    "            # Break condition (achieved convergence)\n",
    "            #if np.sum((beta-beta_old)**2) < eps:\n",
    "            #    break                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel based Models\n",
    "\n",
    "We're just applying the kernel trick to the above models, to have models that can fit non linear like data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.2 ms\n"
     ]
    }
   ],
   "source": [
    "# Weighted Kernel Ridge Regression \n",
    "\n",
    "class ksolveRR_2():\n",
    "    def __init__(self, X, y, lam= 0.1, sample_weights = None, kernel = None):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.kernel = kernel\n",
    "        self.sample_weights = sample_weights\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        if self.sample_weights is not None:\n",
    "            self.X *= self.sample_weights[:, None]\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        A = self.kernel(X, X)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "# Kernel Ridge Regression\n",
    "class ksolveRR():\n",
    "    def __init__(self, X, y, lam= 0.0001, kernel=None):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.kernel = kernel\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "#         if self.sigma is None:\n",
    "#             self.sigma = sigma_from_median(X)\n",
    "            \n",
    "#         A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        A = self.kernel(X, X) + n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "#         K_x = self.kernel(X, self.X, self.sigma)\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Logistic Ridge Regression (LRR)\n",
    "class ksolveLRR():\n",
    "    def __init__(self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=None):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        K = self.kernel(X, X)\n",
    "\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        \n",
    "        # Hint: Use IRLS\n",
    "        for n_iter in range(self.max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*(f))\n",
    "            \n",
    "            alpha = ksolveRR_2(X, y, lam = 2*self.lam, \\\n",
    "                               sigma=self.sigma, sample_weights = w).fit().alpha\n",
    "            \n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < self.tol:\n",
    "                break  \n",
    "                \n",
    "                \n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87.9 ms\n"
     ]
    }
   ],
   "source": [
    "# You don't need to look at this, this is just to adapt our matrices\n",
    "# to the solver being used\n",
    "solver='cvxopt'\n",
    "\n",
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp\n",
    "\n",
    "# def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "#     qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "#     qp_a = -q\n",
    "#     if A is not None:\n",
    "#         qp_C = -np.vstack([A, G]).T\n",
    "#         qp_b = -np.hstack([b, h])\n",
    "#         meq = A.shape[0]\n",
    "#     else:  # no equality constraint\n",
    "#         qp_C = - G.T\n",
    "#         qp_b = - h\n",
    "#         meq = 0\n",
    "#     return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]\n",
    "\n",
    "\n",
    "\n",
    "# solve_qp = {'quadprog': quadprog_solve_qp, 'cvxopt': cvxopt_qp}[solver]\n",
    "\n",
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    A = A.astype('float')\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "# SVM primal soft\n",
    "class KernelSVM():\n",
    "    def __init__(self, X, y, C=0.1, lam = 0.1, tol = 1e-3, kernel=None):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.lam = lam        \n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        C = self.C\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        K = self.kernel(X, X)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        \n",
    "       # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha>self.tol), \\\n",
    "                            (self.C - self.alpha > self.tol))\n",
    "        \n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha*y)\n",
    "        self.bias =  self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where((K_x.dot(self.alpha * self.y) +  self.bias) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62.7 ms\n"
     ]
    }
   ],
   "source": [
    "X_train_ = pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train_ = pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test_ = pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "\n",
    "def spectrum_kernal(X_train, y, X_test, n=2, encoder=8, one_hot = True, normalise = False):\n",
    "    \n",
    "    d = {'A': 1, 'C':2, 'G':3, 'T':4}\n",
    "    \n",
    "    for i in range(0, 101-n+1, 1):\n",
    "        X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+n])\n",
    "        X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+n])\n",
    "        \n",
    "        X_train['seq_'+str(i)] = X_train['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        X_test['seq_'+str(i)] = X_test['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "    X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "    y = Y_train.Bound\n",
    "    \n",
    "#     print(f'Train: \\n{X.tail()}\\n -----------------------\\n')\n",
    "#     print(f'Test: \\n {X_t.tail()}')\n",
    "\n",
    "    if one_hot:\n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore')\n",
    "\n",
    "        X_cross = X.values\n",
    "        X_t = X_t.values\n",
    "        \n",
    "        enc = onehot_encoder.fit(X)\n",
    "        X_cross = enc.transform(X)\n",
    "        X_t_enc = enc.transform(X_t)\n",
    "        \n",
    "    elif normalise:\n",
    "        scaler = MinMaxScaler() #MinMaxScaler() # StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        X_cross = scaler.transform(X)\n",
    "        X_t_enc = scaler.transform(X_t)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        X_cross = X.values\n",
    "        X_t_enc = X_t.values\n",
    "    \n",
    "    y_cross = y.values\n",
    "    \n",
    "    return X_cross, y_cross, X_t_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "def objective_sgd(trial):\n",
    "    \n",
    "    q  = trial.suggest_loguniform('q', 1e-5, 3e+0)\n",
    "    \n",
    "    sigma  = trial.suggest_loguniform('sigma', 1e-1, 8e+0) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    kernel = trial.suggest_categorical('kernel', [0, 8, 4])#[Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                                               #Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen])\n",
    "    \n",
    "#     lam = trial.suggest_loguniform('lam', 1e-15, 1e-4)\n",
    "    \n",
    "#     d = trial.suggest_int('d', 2, 8)\n",
    "    c = trial.suggest_loguniform('c', 1e-2, 5)\n",
    "    \n",
    "    degree = trial.suggest_int('degree', 2, 10)\n",
    "    \n",
    "    # trick to avoid warnning from opma that support only basic datatype\n",
    "    trick_list = [rbf_kernel, Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                        Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen]\n",
    "        \n",
    "    n = trial.suggest_int('n', 1, 3)\n",
    "    \n",
    "    tol = 1e-3 # trial.suggest_loguniform('tol', 1e-7, 1e-0)\n",
    "\n",
    "     \n",
    "    kernels = {rbf_kernel : 'rbf',\n",
    "               Exponential : 'Exponential kernel (self, sigma=None)',\n",
    "               Laplacian : 'Laplacian kernel (self, sigma=None)',\n",
    "               Cauchy : 'Cauchy kernel (self, sigma=None)',\n",
    "               \n",
    "               RationalQuadratic : 'Rational quadratic kernel (self, c=1)',\n",
    "               InverseMultiquadratic : 'Inverse multiquadratic kernel (self, c=1)',\n",
    "               \n",
    "               TStudent : 'T-Student kernel (self, degree=2)',\n",
    "               \n",
    "               ANOVA : 'ANOVA kernel (self, sigma=1., d=2)',\n",
    "               \n",
    "               Fourier : 'Fourier kernel (self, q=0.1)',\n",
    "               \n",
    "               Tanimoto : 'Tanimoto kernel',\n",
    "               Sorensen : 'Sorensen kernel'\n",
    "              }\n",
    "    \n",
    "    if kernels[trick_list[kernel]] == 'ANOVA kernel (self, sigma=sigma, d=d)':\n",
    "        kernel = trick_list[kernel](sigma=sigma, d=d)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'Exponential kernel (self, sigma=None)' or \\\n",
    "                        kernels[trick_list[kernel]] == 'Laplacian kernel (self, sigma=None)' or \\\n",
    "                        kernels[trick_list[kernel]] == 'Cauchy kernel (self, sigma=None)'or \\\n",
    "                        kernels[trick_list[kernel]] == 'rbf':\n",
    "        \n",
    "        kernel = trick_list[kernel](sigma=sigma)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'Rational quadratic kernel (self, c=1)' or \\\n",
    "                        kernels[trick_list[kernel]] == 'Inverse multiquadratic kernel (self, c=1)':\n",
    "        kernel = trick_list[kernel](c=c)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'T-Student kernel (self, degree=2)':\n",
    "        kernel = trick_list[kernel](degree=degree)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'Fourier kernel (self, q=0.1)':\n",
    "        kernel = trick_list[kernel](q=q)\n",
    "        \n",
    "    else:\n",
    "        kernel = trick_list[kernel]()\n",
    "        \n",
    "    \n",
    "#     n = 1\n",
    "    \n",
    "    models = {KernelSVM : 'Kernal SVM'}\n",
    "    \n",
    "\n",
    "    X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=8, one_hot = True, normalise = False)\n",
    "    \n",
    "    for model in models:\n",
    "        accuracy = []\n",
    "        for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "            X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "            X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "            if models[model] == 'weigh Ridge Reg':\n",
    "                sample_weights = np.random.rand(len(y_train))\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kernel)\n",
    "\n",
    "            elif models[model] == 'k Logistic Ridge Reg':\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kernel)\n",
    "            elif models[model] == 'k Ridge Reg':\n",
    "                \n",
    "                model_curr = model(X_train, y_train, lam= lam, kernel=kernel)\n",
    "            elif models[model] == 'log reg':\n",
    "                model_curr = model(lr=lr, num_iter=5000, batch_size=1)\n",
    "            else:\n",
    "                model_curr = model(X_train, y_train, C=c, lam = lam, tol = tol, kernel = kernel)\n",
    "                \n",
    "            if models[model] == 'log reg':\n",
    "                model_curr.fit(X_train, y_train)\n",
    "            else:\n",
    "                model_curr.fit()\n",
    "            \n",
    "\n",
    "            accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "# Uncomment the code bellow to run hypperparameters search \n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "# study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective_sgd, n_trials=1500, show_progress_bar=True)\n",
    "\n",
    "\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print('Accuracy: {}'.format(trial.value))\n",
    "# print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 592 µs\n"
     ]
    }
   ],
   "source": [
    "# print('Accuracy: {}'.format(trial.value))\n",
    "# print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 950 µs\n"
     ]
    }
   ],
   "source": [
    "params = {'sigma': 4.119788517147901, 'lam': 1.2752298700618223e-14} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy fold 0: 0.5975\n",
      "accurracy fold 1: 0.6625\n",
      "accurracy fold 2: 0.68\n",
      "accurracy fold 3: 0.6475\n",
      "accurracy fold 4: 0.7\n",
      "\n",
      "Average accuracy k Ridge Reg is : 0.6575\n",
      "\n",
      "time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "# c  = 0.1\n",
    "\n",
    "# trial.params\n",
    "# sigma  = 5\n",
    "# kenel = 0\n",
    "# lam = 0.0001\n",
    "\n",
    "sigma  = params['sigma'] #4.133127895830191 #4#4.119788517147901 #4.538118805230398\n",
    "kenel = 0 #params['kenel']\n",
    "# q = params['q']\n",
    "# d = params['lam']\n",
    "# c = params['c']\n",
    "# degree = params['degree']\n",
    "lam = params['lam']\n",
    "# model = params['models']\n",
    "\n",
    "trick_list = [rbf_kernel, Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                        Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen]\n",
    "      \n",
    "kernels = {rbf_kernel : 'rbf',\n",
    "           Exponential : 'Exponential kernel (self, sigma=None)',\n",
    "           Laplacian : 'Laplacian kernel (self, sigma=None)',\n",
    "           Cauchy : 'Cauchy kernel (self, sigma=None)',\n",
    "\n",
    "           RationalQuadratic : 'Rational quadratic kernel (self, c=1)',\n",
    "           InverseMultiquadratic : 'Inverse multiquadratic kernel (self, c=1)',\n",
    "\n",
    "           TStudent : 'T-Student kernel (self, degree=2)',\n",
    "\n",
    "           ANOVA : 'ANOVA kernel (self, sigma=1., d=2)',\n",
    "\n",
    "           Fourier : 'Fourier kernel (self, q=0.1)',\n",
    "\n",
    "           Tanimoto : 'Tanimoto kernel',\n",
    "           Sorensen : 'Sorensen kernel'\n",
    "          }\n",
    "\n",
    "if kernels[trick_list[kenel]] == 'ANOVA kernel (self, sigma=sigma, d=d)':\n",
    "        kenel = trick_list[kenel](sigma=sigma, d=d)\n",
    "        \n",
    "elif kernels[trick_list[kenel]] == 'Exponential kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Laplacian kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Cauchy kernel (self, sigma=None)'or \\\n",
    "                    kernels[trick_list[kenel]] == 'rbf':\n",
    "\n",
    "    kenel = trick_list[kenel](sigma=sigma)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Rational quadratic kernel (self, c=1)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Inverse multiquadratic kernel (self, c=1)':\n",
    "    kenel = trick_list[kenel](c=c)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'T-Student kernel (self, degree=2)':\n",
    "    kenel = trick_list[kenel](degree=degree)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Fourier kernel (self, q=0.1)':\n",
    "    kenel = trick_list[kenel](q=q)\n",
    "\n",
    "else:\n",
    "    kenel = trick_list[kenel]()\n",
    "\n",
    "\n",
    "n = 1\n",
    "\n",
    "models = {ksolveRR : 'k Ridge Reg'} \n",
    "\n",
    "X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=8, one_hot = True, normalise = False)\n",
    "\n",
    "for model in models:\n",
    "    accuracy = []\n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "        X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "        X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "        if models[model] == 'weigh Ridge Reg':\n",
    "            sample_weights = np.random.rand(len(y_train))\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "\n",
    "        elif models[model] == 'k Logistic Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "        elif models[model] == 'k Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam= lam, kernel=kenel)\n",
    "        elif models[model] == 'log reg':\n",
    "            model_curr = model(lr=lr, num_iter=5000, batch_size=1)\n",
    "        else:\n",
    "            model_curr = model(X_train, y_train, C=c, lam = lam,\\\n",
    "                               tol= tol, kernel = kenel)\n",
    "\n",
    "        if models[model] == 'log reg':\n",
    "            model_curr.fit(X_train, y_train)\n",
    "        else:\n",
    "            model_curr.fit()\n",
    "\n",
    "\n",
    "        accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "        print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "\n",
    "print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "# Training the model with full data\n",
    "\n",
    "sigma  = params['sigma'] #4.133127895830191 #4#4.119788517147901 #4.538118805230398\n",
    "kenel = 0 #params['kenel']\n",
    "# q = params['q']\n",
    "# d = params['lam']\n",
    "# c = params['c']\n",
    "# degree = params['degree']\n",
    "lam = params['lam']\n",
    "\n",
    "X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=8, one_hot = True, normalise = False)\n",
    "\n",
    "\n",
    "trick_list = [rbf_kernel, Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                        Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen]\n",
    "       \n",
    "kernels = {rbf_kernel : 'rbf',\n",
    "           Exponential : 'Exponential kernel (self, sigma=None)',\n",
    "           Laplacian : 'Laplacian kernel (self, sigma=None)',\n",
    "           Cauchy : 'Cauchy kernel (self, sigma=None)',\n",
    "\n",
    "           RationalQuadratic : 'Rational quadratic kernel (self, c=1)',\n",
    "           InverseMultiquadratic : 'Inverse multiquadratic kernel (self, c=1)',\n",
    "\n",
    "           TStudent : 'T-Student kernel (self, degree=2)',\n",
    "\n",
    "           ANOVA : 'ANOVA kernel (self, sigma=1., d=2)',\n",
    "\n",
    "           Fourier : 'Fourier kernel (self, q=0.1)',\n",
    "\n",
    "           Tanimoto : 'Tanimoto kernel',\n",
    "           Sorensen : 'Sorensen kernel'\n",
    "          }\n",
    "\n",
    "if kernels[trick_list[kenel]] == 'ANOVA kernel (self, sigma=sigma, d=d)':\n",
    "        kenel = trick_list[kenel](sigma=sigma, d=d)\n",
    "        \n",
    "elif kernels[trick_list[kenel]] == 'Exponential kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Laplacian kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Cauchy kernel (self, sigma=None)'or \\\n",
    "                    kernels[trick_list[kenel]] == 'rbf':\n",
    "\n",
    "    kenel = trick_list[kenel](sigma=sigma)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Rational quadratic kernel (self, c=1)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Inverse multiquadratic kernel (self, c=1)':\n",
    "    kenel = trick_list[kenel](c=c)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'T-Student kernel (self, degree=2)':\n",
    "    kenel = trick_list[kenel](degree=degree)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Fourier kernel (self, q=0.1)':\n",
    "    kenel = trick_list[kenel](q=q)\n",
    "\n",
    "else:\n",
    "    kenel = trick_list[kenel]()\n",
    "\n",
    "\n",
    "n = 1\n",
    "\n",
    "models = {ksolveRR : 'k Ridge Reg'} \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    if models[model] == 'weigh Ridge Reg':\n",
    "        sample_weights = np.random.rand(len(y_train))\n",
    "        model_curr = model(X_cross, y_cross, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "\n",
    "    elif models[model] == 'k Logistic Ridge Reg':\n",
    "        model_curr = model(X_cross, y_cross, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "    \n",
    "    elif models[model] == 'k Ridge Reg':\n",
    "        model_curr = model(X_cross, y_cross, lam= lam, kernel=kenel)\n",
    "    \n",
    "    elif models[model] == 'log reg':\n",
    "        model_curr = model(lr=lr, num_iter=5000, batch_size=1)\n",
    "    \n",
    "    else:\n",
    "        model_curr = model(X_cross, y_cross, C=c, lam = lam,\\\n",
    "                           tol= tol, kernel = kenel)\n",
    "\n",
    "    if models[model] == 'log reg':\n",
    "        model_curr.fit(X_cross, y_cross)\n",
    "    \n",
    "    else:\n",
    "        model_curr.fit()\n",
    "            \n",
    "\n",
    "model_curr.Accuracy_check(X_cross, y_cross, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "# Training the model with full data\n",
    "\n",
    "X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=8, one_hot = True, normalise = False)\n",
    "\n",
    "\n",
    "trick_list = [rbf_kernel, Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                        Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen]\n",
    "       \n",
    "kernels = {rbf_kernel : 'rbf',\n",
    "           Exponential : 'Exponential kernel (self, sigma=None)',\n",
    "           Laplacian : 'Laplacian kernel (self, sigma=None)',\n",
    "           Cauchy : 'Cauchy kernel (self, sigma=None)',\n",
    "\n",
    "           RationalQuadratic : 'Rational quadratic kernel (self, c=1)',\n",
    "           InverseMultiquadratic : 'Inverse multiquadratic kernel (self, c=1)',\n",
    "\n",
    "           TStudent : 'T-Student kernel (self, degree=2)',\n",
    "\n",
    "           ANOVA : 'ANOVA kernel (self, sigma=1., d=2)',\n",
    "\n",
    "           Fourier : 'Fourier kernel (self, q=0.1)',\n",
    "\n",
    "           Tanimoto : 'Tanimoto kernel',\n",
    "           Sorensen : 'Sorensen kernel'\n",
    "          }\n",
    "\n",
    "if kernels[trick_list[kenel]] == 'ANOVA kernel (self, sigma=sigma, d=d)':\n",
    "        kenel = trick_list[kenel](sigma=sigma, d=d)\n",
    "        \n",
    "elif kernels[trick_list[kenel]] == 'Exponential kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Laplacian kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Cauchy kernel (self, sigma=None)'or \\\n",
    "                    kernels[trick_list[kenel]] == 'rbf':\n",
    "\n",
    "    kenel = trick_list[kenel](sigma=sigma)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Rational quadratic kernel (self, c=1)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Inverse multiquadratic kernel (self, c=1)':\n",
    "    kenel = trick_list[kenel](c=c)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'T-Student kernel (self, degree=2)':\n",
    "    kenel = trick_list[kenel](degree=degree)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Fourier kernel (self, q=0.1)':\n",
    "    kenel = trick_list[kenel](q=q)\n",
    "\n",
    "else:\n",
    "    kenel = trick_list[kenel]()\n",
    "\n",
    "\n",
    "n = 1\n",
    "\n",
    "models = {ksolveRR : 'k Ridge Reg'} \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    if models[model] == 'weigh Ridge Reg':\n",
    "        sample_weights = np.random.rand(len(y_train))\n",
    "        model_curr = model(X_cross, y_cross, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "\n",
    "    elif models[model] == 'k Logistic Ridge Reg':\n",
    "        model_curr = model(X_cross, y_cross, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "    \n",
    "    elif models[model] == 'k Ridge Reg':\n",
    "        model_curr = model(X_cross, y_cross, lam= lam, kernel=kenel)\n",
    "    \n",
    "    elif models[model] == 'log reg':\n",
    "        model_curr = model(lr=lr, num_iter=5000, batch_size=1)\n",
    "    \n",
    "    else:\n",
    "        model_curr = model(X_cross, y_cross, C=c, lam = lam,\\\n",
    "                           tol= tol, kernel = kenel)\n",
    "\n",
    "    if models[model] == 'log reg':\n",
    "        model_curr.fit(X_cross, y_cross)\n",
    "    \n",
    "    else:\n",
    "        model_curr.fit()\n",
    "            \n",
    "# Prediction \n",
    "y_pred = model_curr.predict(X_t_enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1000).reshape(-1, 1)\n",
    "sample = pd.DataFrame(data=X, columns=['Id'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.1 ms\n"
     ]
    }
   ],
   "source": [
    "sample['Bound'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Bound\n",
       "995  995      0\n",
       "996  996      0\n",
       "997  997      1\n",
       "998  998      1\n",
       "999  999      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.7 ms\n"
     ]
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 76.5 ms\n"
     ]
    }
   ],
   "source": [
    "sample.to_csv('./ksolveRR_accuracy'+str(np.mean(accuracy))+'_cv_rbf_kernel_sigma_'+str(sigma)+'_lam_'+str(lam)+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
